{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro Passo: Importar Bibliotecas\n",
    "+ Soup\n",
    "+ Pandas\n",
    "+ requests\n",
    "\n",
    "Scrap de site de Meteorologia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header do navegador para evitar erros \n",
    "+ Necessário para raspagem de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição de Variaveis a serem obtidas\n",
    "+ https://portal.inmet.gov.br/ +Dados por Script, Difícil Raspagem+\n",
    "+ https://weather.com +Vale a pena este, bastante opções para busca de facila acesso+"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados do Dia Atual (Modelo)\n",
    "+ Dia Atual seg. 01/01/01 (GOOGLE)\n",
    "+ Sensação Térmica 22°\n",
    "+ Temperatura Min. 20°\n",
    "+ Temperatura Max. 24°\n",
    "+ Chance de Chuva 2%\n",
    "+ Umidade 70%\n",
    "+ Visibilidade 8 KM\n",
    "+ Vento 3 KM/H\n",
    "+ Fase da Lua Minguante\n",
    "+ Nascer do Sol 05:00\n",
    "+ Por do Sol 17:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " quarta-feira, 14 de junho de 2023 \n"
     ]
    }
   ],
   "source": [
    "# Data de Hoje\n",
    "data_hoje = requests.get('https://www.google.com/search?q=data&rlz=1C1SQJL_pt-BRBR998BR998&sxsrf=APwXEdcupV6LQAigM1YJ-8DRy9SGmmyOjw%3A1680127416747&ei=uLUkZO6JLYPM1sQP_teriAo&ved=0ahUKEwjuxeiukoL-AhUDppUCHf7rCqEQ4dUDCBA&uact=5&oq=data&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECCMQJzIECCMQJzIHCAAQigUQQzIOCC4QgAQQsQMQxwEQ0QMyDQgAEIoFELEDEIMBEEMyBwgAEIoFEEMyBQgAEIAEMgsIABCABBCxAxCDATIICAAQgAQQsQMyCwgAEIoFELEDEIMBOgoIABBHENYEELADOgoIABCKBRCwAxBDSgQIQRgAUMsFWMoNYPsSaAFwAXgAgAGDAYgBvwWSAQMwLjaYAQCgAQHIAQrAAQE&sclient=gws-wiz-serp', headers = headers)\n",
    "soup_hoje = BeautifulSoup(data_hoje.content, 'html.parser')\n",
    "data_atual = soup_hoje.find_all('div', class_=\"vk_bk dDoNo FzvWSb\")[0]\n",
    "print(data_atual.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22°\n"
     ]
    }
   ],
   "source": [
    "# Sensação Termica\n",
    "s_termica = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_st = BeautifulSoup(s_termica.content, 'html.parser')\n",
    "sensacao_termica = soup_st.find_all('span', class_=\"TodayDetailsCard--feelsLikeTempValue--2icPt\")[0]\n",
    "print(sensacao_termica.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20°\n"
     ]
    }
   ],
   "source": [
    "# Temperatura Minima\n",
    "t_min = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_tmin = BeautifulSoup(t_min.content, 'html.parser')\n",
    "temperatura_min = soup_tmin.find_all('div', class_=\"Column--tempLo--1uHbC\")[0]\n",
    "print(temperatura_min.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23°\n"
     ]
    }
   ],
   "source": [
    "# Temperatura Maxima\n",
    "t_max = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_tmax = BeautifulSoup(t_max.content, 'html.parser')\n",
    "temperatura_max = soup_tmax.find_all('div', class_=\"Column--temp--1sO_J\")[0]\n",
    "print(temperatura_max.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8%\n"
     ]
    }
   ],
   "source": [
    "# Chance de Chuva\n",
    "chuva = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_chuva = BeautifulSoup(chuva.content, 'html.parser')\n",
    "c_chuva = soup_chuva.find_all('span', class_=\"DailyContent--value--1Jers\")[0]\n",
    "print(c_chuva.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92%\n"
     ]
    }
   ],
   "source": [
    "# Umidade\n",
    "umidade = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_umidade = BeautifulSoup(umidade.content, 'html.parser')\n",
    "umidade_ar = soup_umidade.find_all('span', class_=\"DetailsTable--value--2YD0-\")[0]\n",
    "print(umidade_ar.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 KM/H\n"
     ]
    }
   ],
   "source": [
    "# Visibilidade\n",
    "visibilidade = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_visibilidade = BeautifulSoup(visibilidade.content, 'html.parser')\n",
    "d_visibilidade = soup_visibilidade.find_all('div', class_=\"WeatherDetailsListItem--wxData--kK35q\")[1]\n",
    "# Separação, Seleção de valor e acrescentando \"KM/H\"\n",
    "distancia_visibilidade = d_visibilidade.text[14] + \" KM/H\"\n",
    "print(distancia_visibilidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lua minguante\n"
     ]
    }
   ],
   "source": [
    "# Fase da Lua\n",
    "f_lua = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_lua = BeautifulSoup(f_lua.content, 'html.parser')\n",
    "fase_lua = soup_lua.find_all('div', class_=\"WeatherDetailsListItem--wxData--kK35q\")[7]\n",
    "print(fase_lua.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:29\n"
     ]
    }
   ],
   "source": [
    "# Nascer do Sol\n",
    "nascer_s = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_n_sol = BeautifulSoup(nascer_s.content, 'html.parser')\n",
    "nascer_sol = soup_n_sol.find_all('div', class_=\"SunriseSunset--sunriseDateItem--H9yAh\")[0]\n",
    "n_sol = nascer_sol.text[8]+nascer_sol.text[9]+nascer_sol.text[10]+nascer_sol.text[11]\n",
    "print(n_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:13\n"
     ]
    }
   ],
   "source": [
    "# Por do Sol\n",
    "nascer_s = requests.get('https://weather.com/pt-BR/clima/hoje/l/d4f77dbfe5ef5c1fe149973557e1da2e067b0cef006139961ff72fcd8b428558', headers = headers)\n",
    "soup_n_sol = BeautifulSoup(nascer_s.content, 'html.parser')\n",
    "nascer_sol = soup_n_sol.find_all('div', class_=\"SunriseSunset--sunriseDateItem--H9yAh\")[1]\n",
    "n_sol = nascer_sol.text[6]+nascer_sol.text[7]+nascer_sol.text[8]+nascer_sol.text[9]+nascer_sol.text[10]\n",
    "print(n_sol)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados dos Próximos 10 Dias (Modelo)\n",
    "+ Dia Ter. 01\n",
    "+ Temperatura Min 20°\n",
    "+ Temperatura Max 25°\n",
    "+ Chance de Chuva 1%\n",
    "+ Vento 2 KM/H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qua. 14\n",
      "qui. 15\n",
      "sex. 16\n",
      "sáb. 17\n",
      "dom. 18\n",
      "seg. 19\n",
      "ter. 20\n",
      "qua. 21\n",
      "qui. 22\n",
      "sex. 23\n",
      "sáb. 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Proximos Dias\n",
    "Dias_s = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_dias = BeautifulSoup(Dias_s.content, 'html.parser')\n",
    "Dias_a = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[0]\n",
    "Dias_a1 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[1]\n",
    "Dias_a2 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[3]\n",
    "Dias_a3 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[5]\n",
    "Dias_a4 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[7]\n",
    "Dias_a5 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[9]\n",
    "Dias_a6 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[11]\n",
    "Dias_a7 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[13]\n",
    "Dias_a8 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[15]\n",
    "Dias_a9 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[17]\n",
    "Dias_a10 = soup_dias.find_all('span', class_=\"DailyContent--daypartDate--3VGlz\")[19]\n",
    "\n",
    "print(f'''+-{Dias_a.text}-+\n",
    "{Dias_a1.text}\n",
    "{Dias_a2.text}\n",
    "{Dias_a3.text}\n",
    "{Dias_a4.text}\n",
    "{Dias_a5.text}\n",
    "{Dias_a6.text}\n",
    "{Dias_a7.text}\n",
    "{Dias_a8.text}\n",
    "{Dias_a9.text}\n",
    "{Dias_a10.text}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++--++\n",
      "27°\n",
      "26°\n",
      "22°\n",
      "22°\n",
      "22°\n",
      "24°\n",
      "25°\n",
      "25°\n",
      "24°\n",
      "23°\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Temperatura Maxima\n",
    "temp_max = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_tmax = BeautifulSoup(temp_max.content, 'html.parser')\n",
    "tmax = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[0]\n",
    "tmax1 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[1]\n",
    "tmax2 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[2]\n",
    "tmax3 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[3]\n",
    "tmax4 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[4]\n",
    "tmax5 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[5]\n",
    "tmax6 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[6]\n",
    "tmax7 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[7]\n",
    "tmax8 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[8]\n",
    "tmax9 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[9]\n",
    "tmax10 = soup_tmax.find_all('span', class_=\"DetailsSummary--highTempValue--3PjlX\")[10]\n",
    "\n",
    "print(f\"\"\"++{tmax.text}++\n",
    "{tmax1.text}\n",
    "{tmax2.text}\n",
    "{tmax3.text}\n",
    "{tmax4.text}\n",
    "{tmax5.text}\n",
    "{tmax6.text}\n",
    "{tmax7.text}\n",
    "{tmax8.text}\n",
    "{tmax9.text}\n",
    "{tmax10.text}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++20°++\n",
      "21°\n",
      "21°\n",
      "19°\n",
      "18°\n",
      "17°\n",
      "18°\n",
      "18°\n",
      "19°\n",
      "19°\n",
      "19°\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Temperatura Minima\n",
    "temp_min = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_tmin = BeautifulSoup(temp_min.content, 'html.parser')\n",
    "tmin = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[0]\n",
    "tmin1 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[1]\n",
    "tmin2 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[2]\n",
    "tmin3 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[3]\n",
    "tmin4 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[4]\n",
    "tmin5 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[5]\n",
    "tmin6 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[6]\n",
    "tmin7 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[7]\n",
    "tmin8 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[8]\n",
    "tmin9 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[9]\n",
    "tmin10 = soup_tmin.find_all('span', class_=\"DetailsSummary--lowTempValue--2tesQ\")[10]\n",
    "\n",
    "print(f\"\"\"++{tmin.text}++\n",
    "{tmin1.text}\n",
    "{tmin2.text}\n",
    "{tmin3.text}\n",
    "{tmin4.text}\n",
    "{tmin5.text}\n",
    "{tmin6.text}\n",
    "{tmin7.text}\n",
    "{tmin8.text}\n",
    "{tmin9.text}\n",
    "{tmin10.text}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++Rain9%++\n",
      "Rain11%\n",
      "Rain47%\n",
      "Rain38%\n",
      "Rain24%\n",
      "Rain32%\n",
      "Rain6%\n",
      "Rain5%\n",
      "Rain10%\n",
      "Rain39%\n",
      "Rain32%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chance de Chuva\n",
    "chance_chuva = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_c_chuva = BeautifulSoup(chance_chuva.content, 'html.parser')\n",
    "c_chuva = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[0]\n",
    "c_chuva1 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[1]\n",
    "c_chuva2 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[2]\n",
    "c_chuva3 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[3]\n",
    "c_chuva4 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[4]\n",
    "c_chuva5 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[5]\n",
    "c_chuva6 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[6]\n",
    "c_chuva7 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[7]\n",
    "c_chuva8 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[8]\n",
    "c_chuva9 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[9]\n",
    "c_chuva10 = soup_c_chuva.find_all('div', class_=\"DetailsSummary--precip--1a98O\")[10]\n",
    "\n",
    "print(f\"\"\"++{c_chuva.text}++\n",
    "{c_chuva1.text}\n",
    "{c_chuva2.text}\n",
    "{c_chuva3.text}\n",
    "{c_chuva4.text}\n",
    "{c_chuva5.text}\n",
    "{c_chuva6.text}\n",
    "{c_chuva7.text}\n",
    "{c_chuva8.text}\n",
    "{c_chuva9.text}\n",
    "{c_chuva10.text}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++NO 7 km/h++\n",
      "E 12 km/h\n",
      "SO 13 km/h\n",
      "OSO 19 km/h\n",
      "OSO 22 km/h\n",
      "SSO 14 km/h\n",
      "E 16 km/h\n",
      "E 14 km/h\n",
      "E 15 km/h\n",
      "O 15 km/h\n",
      "SSE 15 km/h\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Velocidade do Vento\n",
    "velocidade_vento = requests.get('https://weather.com/pt-BR/clima/10dias/l/2296b14bb55ab7fda4172b63b445eface32c94e1ab83bbb1169e2e126845a390', headers = headers)\n",
    "soup_v_vento = BeautifulSoup(velocidade_vento.content, 'html.parser')\n",
    "v_vento = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[0]\n",
    "v_vento1 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[1]\n",
    "v_vento2 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[2]\n",
    "v_vento3 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[3]\n",
    "v_vento4 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[4]\n",
    "v_vento5 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[5]\n",
    "v_vento6 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[6]\n",
    "v_vento7 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[7]\n",
    "v_vento8 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[8]\n",
    "v_vento9 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[9]\n",
    "v_vento10 = soup_v_vento.find_all('span', class_=\"Wind--windWrapper--3Ly7c undefined\")[10]\n",
    "\n",
    "print(f\"\"\"++{v_vento.text}++\n",
    "{v_vento1.text}\n",
    "{v_vento2.text}\n",
    "{v_vento3.text}\n",
    "{v_vento4.text}\n",
    "{v_vento5.text}\n",
    "{v_vento6.text}\n",
    "{v_vento7.text}\n",
    "{v_vento8.text}\n",
    "{v_vento9.text}\n",
    "{v_vento10.text}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log de Dados Salvos\n",
    "with open(data_atual.text+'.txt', 'w') as arquivo:\n",
    "    arquivo.write(valor_dolar.text)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fee86138af1eb0db027abd7ae9811a7a68978550fae5e6e8a2fd892a05f89b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
